

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Load balancing &mdash; envoy tag-v1.7.0 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Outlier detection" href="outlier.html" />
    <link rel="prev" title="Connection pooling" href="connection_pooling.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> envoy
          

          
          </a>

          
            
            
              <div class="version">
                tag-v1.7.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../about_docs.html">About the documentation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../intro.html">Introduction</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../what_is_envoy.html">What is Envoy</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="arch_overview.html">Architecture overview</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="terminology.html">Terminology</a></li>
<li class="toctree-l3"><a class="reference internal" href="threading_model.html">Threading model</a></li>
<li class="toctree-l3"><a class="reference internal" href="listeners.html">Listeners</a></li>
<li class="toctree-l3"><a class="reference internal" href="listener_filters.html">Listener filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="network_filters.html">Network (L3/L4) filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="http_connection_management.html">HTTP connection management</a></li>
<li class="toctree-l3"><a class="reference internal" href="http_filters.html">HTTP filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="http_routing.html">HTTP routing</a></li>
<li class="toctree-l3"><a class="reference internal" href="grpc.html">gRPC</a></li>
<li class="toctree-l3"><a class="reference internal" href="websocket.html">WebSocket support</a></li>
<li class="toctree-l3"><a class="reference internal" href="cluster_manager.html">Cluster manager</a></li>
<li class="toctree-l3"><a class="reference internal" href="service_discovery.html">Service discovery</a></li>
<li class="toctree-l3"><a class="reference internal" href="health_checking.html">Health checking</a></li>
<li class="toctree-l3"><a class="reference internal" href="connection_pooling.html">Connection pooling</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Load balancing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#supported-load-balancers">Supported load balancers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#original-destination">Original destination</a></li>
<li class="toctree-l4"><a class="reference internal" href="#panic-threshold">Panic threshold</a></li>
<li class="toctree-l4"><a class="reference internal" href="#priority-levels">Priority levels</a></li>
<li class="toctree-l4"><a class="reference internal" href="#zone-aware-routing">Zone aware routing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#locality-weighted-load-balancing">Locality weighted load balancing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-balancer-subsets">Load Balancer Subsets</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="outlier.html">Outlier detection</a></li>
<li class="toctree-l3"><a class="reference internal" href="circuit_breaking.html">Circuit breaking</a></li>
<li class="toctree-l3"><a class="reference internal" href="global_rate_limiting.html">Global rate limiting</a></li>
<li class="toctree-l3"><a class="reference internal" href="ssl.html">TLS</a></li>
<li class="toctree-l3"><a class="reference internal" href="statistics.html">Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="runtime.html">Runtime configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="tracing.html">Tracing</a></li>
<li class="toctree-l3"><a class="reference internal" href="tcp_proxy.html">TCP proxy</a></li>
<li class="toctree-l3"><a class="reference internal" href="access_logging.html">Access logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="mongo.html">MongoDB</a></li>
<li class="toctree-l3"><a class="reference internal" href="dynamo.html">DynamoDB</a></li>
<li class="toctree-l3"><a class="reference internal" href="redis.html">Redis</a></li>
<li class="toctree-l3"><a class="reference internal" href="hot_restart.html">Hot restart</a></li>
<li class="toctree-l3"><a class="reference internal" href="dynamic_configuration.html">Dynamic configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="init.html">Initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="draining.html">Draining</a></li>
<li class="toctree-l3"><a class="reference internal" href="scripting.html">Scripting</a></li>
<li class="toctree-l3"><a class="reference internal" href="ext_authz_filter.html">External Authorization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../deployment_types/deployment_types.html">Deployment types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../comparison.html">Comparison to similar systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting_help.html">Getting help</a></li>
<li class="toctree-l2"><a class="reference internal" href="../version_history.html">Version history</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../start/start.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/install.html">Building and installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../configuration/configuration.html">Configuration reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../operations/operations.html">Operations and administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../extending/extending.html">Extending Envoy for custom use cases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api-v1/api.html">v1 API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api-v2/api.html">v2 API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/overview.html">FAQ</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">envoy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../intro.html">Introduction</a> &raquo;</li>
        
          <li><a href="arch_overview.html">Architecture overview</a> &raquo;</li>
        
      <li>Load balancing</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/intro/arch_overview/load_balancing.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="load-balancing">
<span id="arch-overview-load-balancing"></span><h1>Load balancing<a class="headerlink" href="#load-balancing" title="Permalink to this headline">¶</a></h1>
<p>When a filter needs to acquire a connection to a host in an upstream cluster, the cluster manager
uses a load balancing policy to determine which host is selected. The load balancing policies are
pluggable and are specified on a per upstream cluster basis in the <a class="reference internal" href="../../api-v1/cluster_manager/cluster.html#config-cluster-manager-cluster"><span class="std std-ref">configuration</span></a>. Note that if no active health checking policy is <a class="reference internal" href="../../configuration/cluster_manager/cluster_hc.html#config-cluster-manager-cluster-hc"><span class="std std-ref">configured</span></a> for a cluster, all upstream cluster members are considered
healthy.</p>
<div class="section" id="supported-load-balancers">
<span id="arch-overview-load-balancing-types"></span><h2>Supported load balancers<a class="headerlink" href="#supported-load-balancers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="weighted-round-robin">
<span id="arch-overview-load-balancing-types-round-robin"></span><h3>Weighted round robin<a class="headerlink" href="#weighted-round-robin" title="Permalink to this headline">¶</a></h3>
<p>This is a simple policy in which each healthy upstream host is selected in round
robin order. If <a class="reference internal" href="../../api-v2/api/v2/endpoint/endpoint.proto.html#envoy-api-field-endpoint-lbendpoint-load-balancing-weight"><span class="std std-ref">weights</span></a> are assigned to
endpoints in a locality, then a weighted round robin schedule is used, where
higher weighted endpoints will appear more often in the rotation to achieve the
effective weighting.</p>
</div>
<div class="section" id="weighted-least-request">
<span id="arch-overview-load-balancing-types-least-request"></span><h3>Weighted least request<a class="headerlink" href="#weighted-least-request" title="Permalink to this headline">¶</a></h3>
<p>The least request load balancer uses different algorithms depending on whether any of the hosts have
weight greater than 1.</p>
<ul>
<li><p class="first"><em>all weights 1</em>: An O(1) algorithm which selects two random healthy hosts and
picks the host which has fewer active requests (<a class="reference external" href="http://www.eecs.harvard.edu/~michaelm/postscripts/handbook2001.pdf">Research</a> has shown that this
approach is nearly as good as an O(N) full scan). This is also known as P2C (power of two
choices). The P2C load balancer has the property that a host with the highest number of active
requests in the cluster will never receive new requests. It will be allowed to drain until it is
less than or equal to all of the other hosts.</p>
</li>
<li><p class="first"><em>all weights not 1</em>:  If any host in the cluster has a load balancing weight greater than 1, the
load balancer shifts into a mode where it uses a weighted round robin schedule in which weights
are dynamically adjusted based on the host’s request load at the time of selection (weight is
divided by the current active request count. For example, a host with weight 2 and an active
request count of 4 will have a synthetic weight of 2 / 4 = 0.5). This algorithm provides good
balance at steady state but may not adapt to load imbalance as quickly. Additionally, unlike P2C,
a host will never truly drain, though it will receive fewer requests over time.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If all weights are not 1, but are the same (e.g., 42), Envoy will still use the weighted round
robin schedule instead of P2C.</p>
</div>
</li>
</ul>
</div>
<div class="section" id="ring-hash">
<span id="arch-overview-load-balancing-types-ring-hash"></span><h3>Ring hash<a class="headerlink" href="#ring-hash" title="Permalink to this headline">¶</a></h3>
<p>The ring/modulo hash load balancer implements consistent hashing to upstream hosts. The algorithm is
based on mapping all hosts onto a circle such that the addition or removal of a host from the host
set changes only affect 1/N requests. This technique is also commonly known as <a class="reference external" href="https://github.com/RJ/ketama">“ketama”</a> hashing. A consistent hashing load balancer is only effective
when protocol routing is used that specifies a value to hash on. The minimum ring size governs the
replication factor for each host in the ring. For example, if the minimum ring size is 1024 and
there are 16 hosts, each host will be replicated 64 times. The ring hash load balancer does not
currently support weighting.</p>
<p>When priority based load balancing is in use, the priority level is also chosen by hash, so the
endpoint selected will still be consistent when the set of backends is stable.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The ring hash load balancer does not support <a class="reference internal" href="#arch-overview-load-balancing-locality-weighted-lb"><span class="std std-ref">locality weighted load
balancing</span></a>.</p>
</div>
</div>
<div class="section" id="maglev">
<span id="arch-overview-load-balancing-types-maglev"></span><h3>Maglev<a class="headerlink" href="#maglev" title="Permalink to this headline">¶</a></h3>
<p>The Maglev load balancer implements consistent hashing to upstream hosts. It uses the algorithm
described in section 3.4 of <a class="reference external" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44824.pdf">this paper</a>
with a fixed table size of 65537 (see section 5.3 of the same paper). Maglev can be used as a drop
in replacement for the <a class="reference internal" href="#arch-overview-load-balancing-types-ring-hash"><span class="std std-ref">ring hash load balancer</span></a>
any place in which consistent hashing is desired. Like the ring hash load balancer, a consistent
hashing load balancer is only effective when protocol routing is used that specifies a value to
hash on.</p>
<p>In general, when compared to the ring hash (“ketama”) algorithm, Maglev has substantially faster
table lookup build times as well as host selection times (approximately 10x and 5x respectively
when using a large ring size of 256K entries). The downside of Maglev is that it is not as stable
as ring hash. More keys will move position when hosts are removed (simulations show approximately
double the keys will move). With that said, for many applications including Redis, Maglev is very
likely a superior drop in replacement for ring hash. The advanced reader can use
<a class="reference external" href="https://github.com/envoyproxy/envoy/blob/master//test/common/upstream/load_balancer_benchmark.cc">this benchmark</a> to compare ring hash
versus Maglev with different parameters.</p>
</div>
<div class="section" id="random">
<span id="arch-overview-load-balancing-types-random"></span><h3>Random<a class="headerlink" href="#random" title="Permalink to this headline">¶</a></h3>
<p>The random load balancer selects a random healthy host. The random load balancer generally performs
better than round robin if no health checking policy is configured. Random selection avoids bias
towards the host in the set that comes after a failed host.</p>
</div>
</div>
<div class="section" id="original-destination">
<span id="arch-overview-load-balancing-types-original-destination"></span><h2>Original destination<a class="headerlink" href="#original-destination" title="Permalink to this headline">¶</a></h2>
<p>This is a special purpose load balancer that can only be used with <a class="reference internal" href="service_discovery.html#arch-overview-service-discovery-types-original-destination"><span class="std std-ref">an original destination
cluster</span></a>. Upstream host is selected
based on the downstream connection metadata, i.e., connections are opened to the same address as the
destination address of the incoming connection was before the connection was redirected to
Envoy. New destinations are added to the cluster by the load balancer on-demand, and the cluster
<a class="reference internal" href="../../api-v1/cluster_manager/cluster.html#config-cluster-manager-cluster-cleanup-interval-ms"><span class="std std-ref">periodically</span></a> cleans out unused hosts
from the cluster. No other <a class="reference internal" href="../../api-v1/cluster_manager/cluster.html#config-cluster-manager-cluster-lb-type"><span class="std std-ref">load balancing type</span></a> can
be used with original destination clusters.</p>
<div class="section" id="original-destination-host-request-header">
<span id="arch-overview-load-balancing-types-original-destination-request-header"></span><h3>Original destination host request header<a class="headerlink" href="#original-destination-host-request-header" title="Permalink to this headline">¶</a></h3>
<p>Envoy can also pick up the original destination from a HTTP header called <code class="docutils literal notranslate"><span class="pre">x-envoy-original-destination-host</span></code>.
Please note that fully resolved IP address should be passed in this header. For example if a request has to be
routed to a host with IP address 10.195.16.237 at port 8888, the request header value should be set as
<code class="docutils literal notranslate"><span class="pre">10.195.16.237:8888</span></code>.</p>
</div>
</div>
<div class="section" id="panic-threshold">
<span id="arch-overview-load-balancing-panic-threshold"></span><h2>Panic threshold<a class="headerlink" href="#panic-threshold" title="Permalink to this headline">¶</a></h2>
<p>During load balancing, Envoy will generally only consider healthy hosts in an upstream cluster.
However, if the percentage of healthy hosts in the cluster becomes too low, Envoy will disregard
health status and balance amongst all hosts. This is known as the <em>panic threshold</em>. The default
panic threshold is 50%. This is <a class="reference internal" href="../../configuration/cluster_manager/cluster_runtime.html#config-cluster-manager-cluster-runtime"><span class="std std-ref">configurable</span></a> via
runtime as well as in the <a class="reference internal" href="../../api-v2/api/v2/cds.proto.html#envoy-api-field-cluster-commonlbconfig-healthy-panic-threshold"><span class="std std-ref">cluster configuration</span></a>. The panic threshold
is used to avoid a situation in which host failures cascade throughout the cluster as load
increases.</p>
<p>Note that panic thresholds are <em>per-priority</em>. This means that if the percentage of healthy nodes
in a single priority goes below the threshold, that priority will enter panic mode. In general
it is discouraged to use panic thresholds in conjunction with priorities, as by the time enough
nodes are unhealthy to trigger the panic threshold most of the traffic should already have spilled
over to the next priority level.</p>
</div>
<div class="section" id="priority-levels">
<span id="arch-overview-load-balancing-priority-levels"></span><h2>Priority levels<a class="headerlink" href="#priority-levels" title="Permalink to this headline">¶</a></h2>
<p>During load balancing, Envoy will generally only consider hosts configured at the highest priority
level. For each EDS <a class="reference internal" href="../../api-v2/api/v2/endpoint/endpoint.proto.html#envoy-api-msg-endpoint-localitylbendpoints"><span class="std std-ref">LocalityLbEndpoints</span></a> an optional
priority may also be specified. When endpoints at the highest priority level (P=0) are healthy, all
traffic will land on endpoints in that priority level. As endpoints for the highest priority level
become unhealthy, traffic will begin to trickle to lower priority levels.</p>
<p>Currently, it is assumed that each priority level is over-provisioned by a (hard-coded) factor of
1.4. So if 80% of the endpoints are healthy, the priority level is still considered healthy because
80*1.4 &gt; 100. As the number of healthy endpoints dips below 72%, the health of the priority level
goes below 100. At that point the percent of traffic equivalent to the health of P=0 will go to P=0
and remaining traffic will flow to P=1.</p>
<p>Assume a simple set-up with 2 priority levels, P=1 100% healthy.</p>
<table border="1" class="docutils">
<colgroup>
<col width="34%" />
<col width="33%" />
<col width="34%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">P=0 healthy endpoints</th>
<th class="head">Percent of traffic to P=0</th>
<th class="head">Percent of traffic to P=1</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>100%</td>
<td>100%</td>
<td>0%</td>
</tr>
<tr class="row-odd"><td>72%</td>
<td>100%</td>
<td>0%</td>
</tr>
<tr class="row-even"><td>71%</td>
<td>99%</td>
<td>1%</td>
</tr>
<tr class="row-odd"><td>50%</td>
<td>70%</td>
<td>30%</td>
</tr>
<tr class="row-even"><td>25%</td>
<td>35%</td>
<td>65%</td>
</tr>
<tr class="row-odd"><td>0%</td>
<td>0%</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>If P=1 becomes unhealthy, it will continue to take spilled load from P=0 until the sum of the health
P=0 + P=1 goes below 100. At this point the healths will be scaled up to an “effective” health of
100%.</p>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="30%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">P=0 healthy endpoints</th>
<th class="head">P=1 healthy endpoints</th>
<th class="head">Traffic to  P=0</th>
<th class="head">Traffic to P=1</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>100%</td>
<td>100%</td>
<td>100%</td>
<td>0%</td>
</tr>
<tr class="row-odd"><td>72%</td>
<td>72%</td>
<td>100%</td>
<td>0%</td>
</tr>
<tr class="row-even"><td>71%</td>
<td>71%</td>
<td>99%</td>
<td>1%</td>
</tr>
<tr class="row-odd"><td>50%</td>
<td>50%</td>
<td>70%</td>
<td>30%</td>
</tr>
<tr class="row-even"><td>25%</td>
<td>100%</td>
<td>35%</td>
<td>65%</td>
</tr>
<tr class="row-odd"><td>25%</td>
<td>25%</td>
<td>50%</td>
<td>50%</td>
</tr>
</tbody>
</table>
<p>As more priorities are added, each level consumes load equal to its “scaled” effective health, so
P=2 would only receive traffic if the combined health of P=0 + P=1 was less than 100.</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">P=0 healthy endpoints</th>
<th class="head">P=1 healthy endpoints</th>
<th class="head">P=2 healthy endpoints</th>
<th class="head">Traffic to P=0</th>
<th class="head">Traffic to P=1</th>
<th class="head">Traffic to P=2</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>100%</td>
<td>100%</td>
<td>100%</td>
<td>100%</td>
<td>0%</td>
<td>0%</td>
</tr>
<tr class="row-odd"><td>72%</td>
<td>72%</td>
<td>100%</td>
<td>100%</td>
<td>0%</td>
<td>0%</td>
</tr>
<tr class="row-even"><td>71%</td>
<td>71%</td>
<td>100%</td>
<td>99%</td>
<td>1%</td>
<td>0%</td>
</tr>
<tr class="row-odd"><td>50%</td>
<td>50%</td>
<td>100%</td>
<td>70%</td>
<td>30%</td>
<td>0%</td>
</tr>
<tr class="row-even"><td>25%</td>
<td>100%</td>
<td>100%</td>
<td>35%</td>
<td>65%</td>
<td>0%</td>
</tr>
<tr class="row-odd"><td>25%</td>
<td>25%</td>
<td>100%</td>
<td>25%</td>
<td>25%</td>
<td>50%</td>
</tr>
</tbody>
</table>
<p>To sum this up in pseudo algorithms:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">load</span> <span class="n">to</span> <span class="n">P_0</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">health</span><span class="p">(</span><span class="n">P_0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="n">total_health</span><span class="p">)</span>
<span class="n">health</span><span class="p">(</span><span class="n">P_X</span><span class="p">)</span> <span class="o">=</span> <span class="mi">140</span> <span class="o">*</span> <span class="n">healthy_P_X_backends</span> <span class="o">/</span> <span class="n">total_P_X_backends</span>
<span class="n">total_health</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">Σ</span><span class="p">(</span><span class="n">health</span><span class="p">(</span><span class="n">P_0</span><span class="p">)</span><span class="o">...</span><span class="n">health</span><span class="p">(</span><span class="n">P_X</span><span class="p">))</span>
<span class="n">load</span> <span class="n">to</span> <span class="n">P_X</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="n">Σ</span><span class="p">(</span><span class="n">percent_load</span><span class="p">(</span><span class="n">P_0</span><span class="p">)</span><span class="o">..</span><span class="n">percent_load</span><span class="p">(</span><span class="n">P_X</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="zone-aware-routing">
<span id="arch-overview-load-balancing-zone-aware-routing"></span><h2>Zone aware routing<a class="headerlink" href="#zone-aware-routing" title="Permalink to this headline">¶</a></h2>
<p>We use the following terminology:</p>
<ul class="simple">
<li><strong>Originating/Upstream cluster</strong>: Envoy routes requests from an originating cluster to an upstream
cluster.</li>
<li><strong>Local zone</strong>: The same zone that contains a subset of hosts in both the originating and
upstream clusters.</li>
<li><strong>Zone aware routing</strong>: Best effort routing of requests to an upstream cluster host in the local
zone.</li>
</ul>
<p>In deployments where hosts in originating and upstream clusters belong to different zones
Envoy performs zone aware routing. There are several preconditions before zone aware routing can be
performed:</p>
<ul class="simple" id="arch-overview-load-balancing-zone-aware-routing-preconditions">
<li>Both originating and upstream cluster are not in
<a class="reference internal" href="#arch-overview-load-balancing-panic-threshold"><span class="std std-ref">panic mode</span></a>.</li>
<li>Zone aware <a class="reference internal" href="../../configuration/cluster_manager/cluster_runtime.html#config-cluster-manager-cluster-runtime-zone-routing"><span class="std std-ref">routing is enabled</span></a>.</li>
<li>The originating cluster has the same number of zones as the upstream cluster.</li>
<li>The upstream cluster has enough hosts. See
<a class="reference internal" href="../../configuration/cluster_manager/cluster_runtime.html#config-cluster-manager-cluster-runtime-zone-routing"><span class="std std-ref">here</span></a> for more information.</li>
</ul>
<p>The purpose of zone aware routing is to send as much traffic to the local zone in the upstream
cluster as possible while roughly maintaining the same number of requests per second across all
upstream hosts (depending on load balancing policy).</p>
<p>Envoy tries to push as much traffic as possible to the local upstream zone as long as
roughly the same number of requests per host in the upstream cluster are maintained. The decision of
whether Envoy routes to the local zone or performs cross zone routing depends on the percentage of
healthy hosts in the originating cluster and upstream cluster in the local zone. There are two cases
with regard to percentage relations in the local zone between originating and upstream clusters:</p>
<ul class="simple">
<li>The originating cluster local zone percentage is greater than the one in the upstream cluster.
In this case we cannot route all requests from the local zone of the originating cluster to the
local zone of the upstream cluster because that will lead to request imbalance across all upstream
hosts. Instead, Envoy calculates the percentage of requests that can be routed directly to the
local zone of the upstream cluster. The rest of the requests are routed cross zone. The specific
zone is selected based on the residual capacity of the zone (that zone will get some local zone
traffic and may have additional capacity Envoy can use for cross zone traffic).</li>
<li>The originating cluster local zone percentage is smaller than the one in upstream cluster.
In this case the local zone of the upstream cluster can get all of the requests from the
local zone of the originating cluster and also have some space to allow traffic from other zones
in the originating cluster (if needed).</li>
</ul>
<p>Note that when using multiple priorities, zone aware routing is currently only supported for P=0.</p>
</div>
<div class="section" id="locality-weighted-load-balancing">
<span id="arch-overview-load-balancing-locality-weighted-lb"></span><h2>Locality weighted load balancing<a class="headerlink" href="#locality-weighted-load-balancing" title="Permalink to this headline">¶</a></h2>
<p>Another approach to determining how to weight assignments across different zones
and geographical locations is by using explicit weights supplied via EDS in the
<a class="reference internal" href="../../api-v2/api/v2/endpoint/endpoint.proto.html#envoy-api-msg-endpoint-localitylbendpoints"><span class="std std-ref">LocalityLbEndpoints</span></a> message.
This approach is mutually exclusive with the above zone aware routing, since in
the case of locality aware LB, we rely on the management server to provide the
locality weighting, rather than the Envoy-side heuristics used in zone aware
routing.</p>
<p>When all endpoints are healthy, the locality is picked using a weighted
round-robin schedule, where the locality weight is used for weighting. When some
endpoints in a locality are unhealthy, we adjust the locality weight to reflect
this. As with <a class="reference internal" href="#arch-overview-load-balancing-priority-levels"><span class="std std-ref">priority levels</span></a>, we assume an over-provision
factor (currently hardcoded at 1.4), which means we do not perform any weight
adjustment when only a small number of endpoints in a locality are unhealthy.</p>
<p>Assume a simple set-up with 2 localities X and Y, where X has a locality weight
of 1 and Y has a locality weight of 2, L=Y 100% healthy.</p>
<table border="1" class="docutils">
<colgroup>
<col width="34%" />
<col width="33%" />
<col width="34%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">L=X healthy endpoints</th>
<th class="head">Percent of traffic to L=X</th>
<th class="head">Percent of traffic to L=Y</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>100%</td>
<td>33%</td>
<td>67%</td>
</tr>
<tr class="row-odd"><td>70%</td>
<td>33%</td>
<td>67%</td>
</tr>
<tr class="row-even"><td>69%</td>
<td>32%</td>
<td>68%</td>
</tr>
<tr class="row-odd"><td>50%</td>
<td>26%</td>
<td>74%</td>
</tr>
<tr class="row-even"><td>25%</td>
<td>15%</td>
<td>85%</td>
</tr>
<tr class="row-odd"><td>0%</td>
<td>0%</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p>To sum this up in pseudo algorithms:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">health</span><span class="p">(</span><span class="n">L_X</span><span class="p">)</span> <span class="o">=</span> <span class="mi">140</span> <span class="o">*</span> <span class="n">healthy_X_backends</span> <span class="o">/</span> <span class="n">total_X_backends</span>
<span class="n">effective_weight</span><span class="p">(</span><span class="n">L_X</span><span class="p">)</span> <span class="o">=</span> <span class="n">locality_weight_X</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">health</span><span class="p">(</span><span class="n">L_X</span><span class="p">))</span>
<span class="n">load</span> <span class="n">to</span> <span class="n">L_X</span> <span class="o">=</span> <span class="n">effective_weight</span><span class="p">(</span><span class="n">L_X</span><span class="p">)</span> <span class="o">/</span> <span class="n">Σ_c</span><span class="p">(</span><span class="n">effective_weight</span><span class="p">(</span><span class="n">L_c</span><span class="p">))</span>
</pre></div>
</div>
<p>Note that the locality weighted pick takes place after the priority level is
picked. The load balancer follows these steps:</p>
<ol class="arabic simple">
<li>Pick <a class="reference internal" href="#arch-overview-load-balancing-priority-levels"><span class="std std-ref">priority level</span></a>.</li>
<li>Pick locality (as described in this section) within priority level from (1).</li>
<li>Pick endpoint using cluster specified load balancer within locality from (2).</li>
</ol>
<p>Locality weighted load balancing is configured by setting
<a class="reference internal" href="../../api-v2/api/v2/cds.proto.html#envoy-api-field-cluster-commonlbconfig-locality-weighted-lb-config"><span class="std std-ref">locality_weighted_lb_config</span></a> in the
cluster configuration and providing weights in <a class="reference internal" href="../../api-v2/api/v2/endpoint/endpoint.proto.html#envoy-api-msg-endpoint-localitylbendpoints"><span class="std std-ref">LocalityLbEndpoints</span></a> via <a class="reference internal" href="../../api-v2/api/v2/endpoint/endpoint.proto.html#envoy-api-field-endpoint-localitylbendpoints-load-balancing-weight"><span class="std std-ref">load_balancing_weight</span></a>.</p>
<p>This feature is not compatible with <a class="reference internal" href="#arch-overview-load-balancer-subsets"><span class="std std-ref">load balancer subsetting</span></a>, since it is not straightforward to
reconcile locality level weighting with sensible weights for individual subsets.</p>
</div>
<div class="section" id="load-balancer-subsets">
<span id="arch-overview-load-balancer-subsets"></span><h2>Load Balancer Subsets<a class="headerlink" href="#load-balancer-subsets" title="Permalink to this headline">¶</a></h2>
<p>Envoy may be configured to divide hosts within an upstream cluster into subsets based on metadata
attached to the hosts. Routes may then specify the metadata that a host must match in order to be
selected by the load balancer, with the option of falling back to a predefined set of hosts,
including any host.</p>
<p>Subsets use the load balancer policy specified by the cluster. The original destination policy may
not be used with subsets because the upstream hosts are not known in advance. Subsets are compatible
with zone aware routing, but be aware that the use of subsets may easily violate the minimum hosts
condition described above.</p>
<p>If subsets are <a class="reference internal" href="../../api-v2/api/v2/cds.proto.html#envoy-api-field-cluster-lb-subset-config"><span class="std std-ref">configured</span></a> and a route
specifies no metadata or no subset matching the metadata exists, the subset load balancer initiates
its fallback policy. The default policy is <code class="docutils literal notranslate"><span class="pre">NO_ENDPOINT</span></code>, in which case the request fails as if
the cluster had no hosts. Conversely, the <code class="docutils literal notranslate"><span class="pre">ANY_ENDPOINT</span></code> fallback policy load balances across all
hosts in the cluster, without regard to host metadata. Finally, the <code class="docutils literal notranslate"><span class="pre">DEFAULT_SUBSET</span></code> causes
fallback to load balance among hosts that match a specific set of metadata.</p>
<p>Subsets must be predefined to allow the subset load balancer to efficiently select the correct
subset of hosts. Each definition is a set of keys, which translates to zero or more
subsets. Conceptually, each host that has a metadata value for all of the keys in a definition is
added to a subset specific to its key-value pairs. If no host has all the keys, no subsets result
from the definition. Multiple definitions may be provided, and a single host may appear in multiple
subsets if it matches multiple definitions.</p>
<p>During routing, the route’s metadata match configuration is used to find a specific subset. If there
is a subset with the exact keys and values specified by the route, the subset is used for load
balancing. Otherwise, the fallback policy is used. The cluster’s subset configuration must,
therefore, contain a definition that has the same keys as a given route in order for subset load
balancing to occur.</p>
<p>This feature can only be enabled using the V2 configuration API. Furthermore, host metadata is only
supported when using the EDS discovery type for clusters. Host metadata for subset load balancing
must be placed under the filter name <code class="docutils literal notranslate"><span class="pre">&quot;envoy.lb&quot;</span></code>. Similarly, route metadata match criteria use
the <code class="docutils literal notranslate"><span class="pre">&quot;envoy.lb&quot;</span></code> filter name. Host metadata may be hierarchical (e.g., the value for a top-level
key may be a structured value or list), but the subset load balancer only compares top-level keys
and values. Therefore when using structured values, a route’s match criteria will only match if an
identical structured value appears in the host’s metadata.</p>
<div class="section" id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h3>
<p>We’ll use simple metadata where all values are strings. Assume the following hosts are defined and
associated with a cluster:</p>
<table border="1" class="docutils">
<colgroup>
<col width="21%" />
<col width="79%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Host</th>
<th class="head">Metadata</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>host1</td>
<td>v: 1.0, stage: prod</td>
</tr>
<tr class="row-odd"><td>host2</td>
<td>v: 1.0, stage: prod</td>
</tr>
<tr class="row-even"><td>host3</td>
<td>v: 1.1, stage: canary</td>
</tr>
<tr class="row-odd"><td>host4</td>
<td>v: 1.2-pre, stage: dev</td>
</tr>
</tbody>
</table>
<p>The cluster may enable subset load balancing like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---</span>
<span class="n">name</span><span class="p">:</span> <span class="n">cluster</span><span class="o">-</span><span class="n">name</span>
<span class="nb">type</span><span class="p">:</span> <span class="n">EDS</span>
<span class="n">eds_cluster_config</span><span class="p">:</span>
  <span class="n">eds_config</span><span class="p">:</span>
    <span class="n">path</span><span class="p">:</span> <span class="s1">&#39;.../eds.conf&#39;</span>
<span class="n">connect_timeout</span><span class="p">:</span>
  <span class="n">seconds</span><span class="p">:</span> <span class="mi">10</span>
<span class="n">lb_policy</span><span class="p">:</span> <span class="n">LEAST_REQUEST</span>
<span class="n">lb_subset_config</span><span class="p">:</span>
  <span class="n">fallback_policy</span><span class="p">:</span> <span class="n">DEFAULT_SUBSET</span>
  <span class="n">default_subset</span><span class="p">:</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">prod</span>
  <span class="n">subset_selectors</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">keys</span><span class="p">:</span>
    <span class="o">-</span> <span class="n">v</span>
    <span class="o">-</span> <span class="n">stage</span>
  <span class="o">-</span> <span class="n">keys</span><span class="p">:</span>
    <span class="o">-</span> <span class="n">stage</span>
</pre></div>
</div>
<p>The following table describes some routes and the result of their application to the
cluster. Typically the match criteria would be used with routes matching specific aspects of the
request, such as the path or header information.</p>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="17%" />
<col width="55%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Match Criteria</th>
<th class="head">Balances Over</th>
<th class="head">Reason</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>stage: canary</td>
<td>host3</td>
<td>Subset of hosts selected</td>
</tr>
<tr class="row-odd"><td>v: 1.2-pre, stage: dev</td>
<td>host4</td>
<td>Subset of hosts selected</td>
</tr>
<tr class="row-even"><td>v: 1.0</td>
<td>host1, host2</td>
<td>Fallback: No subset selector for “v” alone</td>
</tr>
<tr class="row-odd"><td>other: x</td>
<td>host1, host2</td>
<td>Fallback: No subset selector for “other”</td>
</tr>
<tr class="row-even"><td>(none)</td>
<td>host1, host2</td>
<td>Fallback: No subset requested</td>
</tr>
</tbody>
</table>
<p>Metadata match criteria may also be specified on a route’s weighted clusters. Metadata match
criteria from the selected weighted cluster are merged with and override the criteria from the
route:</p>
<table border="1" class="docutils">
<colgroup>
<col width="28%" />
<col width="43%" />
<col width="29%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Route Match Criteria</th>
<th class="head">Weighted Cluster Match Criteria</th>
<th class="head">Final Match Criteria</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>stage: canary</td>
<td>stage: prod</td>
<td>stage: prod</td>
</tr>
<tr class="row-odd"><td>v: 1.0</td>
<td>stage: prod</td>
<td>v: 1.0, stage: prod</td>
</tr>
<tr class="row-even"><td>v: 1.0, stage: prod</td>
<td>stage: canary</td>
<td>v: 1.0, stage: canary</td>
</tr>
<tr class="row-odd"><td>v: 1.0, stage: prod</td>
<td>v: 1.1, stage: canary</td>
<td>v: 1.1, stage: canary</td>
</tr>
<tr class="row-even"><td>(none)</td>
<td>v: 1.0</td>
<td>v: 1.0</td>
</tr>
<tr class="row-odd"><td>v: 1.0</td>
<td>(none)</td>
<td>v: 1.0</td>
</tr>
</tbody>
</table>
<div class="section" id="example-host-with-metadata">
<h4>Example Host With Metadata<a class="headerlink" href="#example-host-with-metadata" title="Permalink to this headline">¶</a></h4>
<p>An EDS <code class="docutils literal notranslate"><span class="pre">LbEndpoint</span></code> with host metadata:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---</span>
<span class="n">endpoint</span><span class="p">:</span>
  <span class="n">address</span><span class="p">:</span>
    <span class="n">socket_address</span><span class="p">:</span>
      <span class="n">protocol</span><span class="p">:</span> <span class="n">TCP</span>
      <span class="n">address</span><span class="p">:</span> <span class="mf">127.0</span><span class="o">.</span><span class="mf">0.1</span>
      <span class="n">port_value</span><span class="p">:</span> <span class="mi">8888</span>
<span class="n">metadata</span><span class="p">:</span>
  <span class="n">filter_metadata</span><span class="p">:</span>
    <span class="n">envoy</span><span class="o">.</span><span class="n">lb</span><span class="p">:</span>
      <span class="n">version</span><span class="p">:</span> <span class="s1">&#39;1.0&#39;</span>
      <span class="n">stage</span><span class="p">:</span> <span class="s1">&#39;prod&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="example-route-with-metadata-criteria">
<h4>Example Route With Metadata Criteria<a class="headerlink" href="#example-route-with-metadata-criteria" title="Permalink to this headline">¶</a></h4>
<p>An RDS <code class="docutils literal notranslate"><span class="pre">Route</span></code> with metadata match criteria:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">---</span>
<span class="n">match</span><span class="p">:</span>
  <span class="n">prefix</span><span class="p">:</span> <span class="o">/</span>
<span class="n">route</span><span class="p">:</span>
  <span class="n">cluster</span><span class="p">:</span> <span class="n">cluster</span><span class="o">-</span><span class="n">name</span>
  <span class="n">metadata_match</span><span class="p">:</span>
    <span class="n">filter_metadata</span><span class="p">:</span>
      <span class="n">envoy</span><span class="o">.</span><span class="n">lb</span><span class="p">:</span>
        <span class="n">version</span><span class="p">:</span> <span class="s1">&#39;1.0&#39;</span>
        <span class="n">stage</span><span class="p">:</span> <span class="s1">&#39;prod&#39;</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="outlier.html" class="btn btn-neutral float-right" title="Outlier detection" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="connection_pooling.html" class="btn btn-neutral" title="Connection pooling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016-2018, Envoy Project Authors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'tag-v1.7.0',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>